{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract User-Submitted CellRanger Sample-Level Data from OSD/GLDS-352.**\n",
    "\n",
    "\n",
    "**CellRanger command:**\n",
    "- From OSD-352 user-submitted data\n",
    "- Used Cellranger Arc 2.0.0 for data processing\n",
    "- The code for the complete analysis pipeline is provided under the github repository: https://github.com/giacomellolab/NASA_RR3_Brain/tree/main/multiomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract GEX barcodes from all cells from each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of sample file names and corresponding output file names\n",
    "sample_files = [\n",
    "    'CF1_per_barcode_metrics_wellID5.csv',\n",
    "    'CF2_per_barcode_metrics_wellID1.csv',\n",
    "    'CF7_per_barcode_metrics_wellID2.csv',\n",
    "    'CG8_per_barcode_metrics_wellID3.csv',\n",
    "    'CG9_per_barcode_metrics_wellID4.csv'\n",
    "]\n",
    "\n",
    "output_files = [\n",
    "    'CF1_gex_barcodes_for_cells.csv',\n",
    "    'CF2_gex_barcodes_for_cells.csv',\n",
    "    'CF7_gex_barcodes_for_cells.csv',\n",
    "    'CG8_gex_barcodes_for_cells.csv',\n",
    "    'CG9_gex_barcodes_for_cells.csv'\n",
    "]\n",
    "\n",
    "output_atac_files = [\n",
    "    'CF1_atac_barcodes_for_cells.csv',\n",
    "    'CF2_atac_barcodes_for_cells.csv',\n",
    "    'CF7_atac_barcodes_for_cells.csv',\n",
    "    'CG8_atac_barcodes_for_cells.csv',\n",
    "    'CG9_atac_barcodes_for_cells.csv'\n",
    "]\n",
    "\n",
    "# Process each sample file\n",
    "for sample_file, output_file, output_atac_file in zip(sample_files, output_files, output_atac_files):\n",
    "    # Load the metadata CSV file\n",
    "    metadata_df = pd.read_csv(sample_file)\n",
    "    \n",
    "    # Filter rows where 'is_cell' is 1\n",
    "    cell_metadata_df = metadata_df[metadata_df['is_cell'] == 1]\n",
    "    \n",
    "    # Extract the 'gex_barcode' column\n",
    "    gex_barcodes = cell_metadata_df['gex_barcode']\n",
    "    atac_barcodes = cell_metadata_df['atac_barcode']\n",
    "    \n",
    "    # Verify the number of cells\n",
    "    print(f\"Number of cells in {sample_file}: {len(gex_barcodes)}\")  # Should match the expected count\n",
    "    print(f\"Number of atac cells in {sample_file}: {len(atac_barcodes)}\")  # Should match the expected count\n",
    "    \n",
    "    # Save the gex_barcodes to a file\n",
    "    gex_barcodes.to_csv(output_file, index=False, header=False)\n",
    "    print(f\"Saved {output_file}\")\n",
    "    atac_barcodes.to_csv(output_atac_file, index=False, header=False)\n",
    "\n",
    "# After running the code, the gex barcode files will be saved in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your files\n",
    "h5_filename = 'GLDS-352_snRNA-Seq_filtered_feature_bc_matrix.h5'  # Replace with your .h5 file path\n",
    "csv_filenames = [\n",
    "    'CF1_gex_barcodes_for_cells.csv',\n",
    "    'CF2_gex_barcodes_for_cells.csv',\n",
    "    'CF7_gex_barcodes_for_cells.csv',\n",
    "    'CG8_gex_barcodes_for_cells.csv',\n",
    "    'CG9_gex_barcodes_for_cells.csv'\n",
    "]\n",
    "csv_atac_filenames = [\n",
    "    'CF1_atac_barcodes_for_cells.csv',\n",
    "    'CF2_atac_barcodes_for_cells.csv',\n",
    "    'CF7_atac_barcodes_for_cells.csv',\n",
    "    'CG8_atac_barcodes_for_cells.csv',\n",
    "    'CG9_atac_barcodes_for_cells.csv'\n",
    "\n",
    "]\n",
    "sample_names = ['CF1', 'CF2', 'CF7', 'CG8', 'CG9']\n",
    "output_base_dir = 'CR_output'  # Replace with your desired output base directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up functions to extract sample-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read HDF5 file\n",
    "def read_h5_file(h5_filename):\n",
    "    with h5py.File(h5_filename, 'r') as f:\n",
    "        barcodes = f['matrix']['barcodes'][()]\n",
    "        barcodes = [barcode.decode('utf-8') for barcode in barcodes]\n",
    "        \n",
    "        features = f['matrix']['features']['name'][()]\n",
    "        feature_ids = f['matrix']['features']['id'][()]\n",
    "        feature_types = f['matrix']['features']['feature_type'][()]\n",
    "        \n",
    "        data = f['matrix']['data'][()]\n",
    "        indices = f['matrix']['indices'][()]\n",
    "        indptr = f['matrix']['indptr'][()]\n",
    "        shape = f['matrix']['shape'][()]\n",
    "        \n",
    "    return barcodes, features, feature_ids, feature_types, data, indices, indptr, shape\n",
    "\n",
    "# Function to write TSV and MTX files\n",
    "def write_files_by_well_ID(barcodes, features, feature_ids, feature_types, data, indices, indptr, shape, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    sample_indices = [i for i, barcode in enumerate(barcodes) if barcode in sample_barcodes]\n",
    "    filtered_data = []\n",
    "    filtered_indices = []\n",
    "    filtered_indptr = [0]\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        start = indptr[idx]\n",
    "        end = indptr[idx + 1]\n",
    "        filtered_data.extend(data[start:end])\n",
    "        filtered_indices.extend(indices[start:end])\n",
    "        filtered_indptr.append(len(filtered_data))\n",
    "    \n",
    "    filtered_shape = (shape[0], len(sample_indices))\n",
    "\n",
    "    with open(os.path.join(output_dir, 'barcodes.tsv'), 'w') as bfile:\n",
    "        bfile.write('\\n'.join(sample_barcodes) + '\\n')\n",
    "\n",
    "    with open(os.path.join(output_dir, 'features.tsv'), 'w') as ffile:\n",
    "        for i in range(len(features)):\n",
    "            ffile.write(f\"{feature_ids[i].decode('utf-8')}\\t{features[i].decode('utf-8')}\\t{feature_types[i].decode('utf-8')}\\n\")\n",
    "\n",
    "    scipy.io.mmwrite(os.path.join(output_dir, 'matrix.mtx'), \n",
    "                     scipy.sparse.csc_matrix((filtered_data, filtered_indices, filtered_indptr), shape=filtered_shape))\n",
    "\n",
    "# Function to write TSV and MTX files\n",
    "def write_files(barcodes, features, feature_ids, feature_types, data, indices, indptr, shape, sample_barcodes, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    sample_indices = [i for i, barcode in enumerate(barcodes) if barcode in sample_barcodes]\n",
    "    filtered_data = []\n",
    "    filtered_indices = []\n",
    "    filtered_indptr = [0]\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        start = indptr[idx]\n",
    "        end = indptr[idx + 1]\n",
    "        filtered_data.extend(data[start:end])\n",
    "        filtered_indices.extend(indices[start:end])\n",
    "        filtered_indptr.append(len(filtered_data))\n",
    "    \n",
    "    filtered_shape = (shape[0], len(sample_indices))\n",
    "\n",
    "    with open(os.path.join(output_dir, 'barcodes.tsv'), 'w') as bfile:\n",
    "        bfile.write('\\n'.join(sample_barcodes) + '\\n')\n",
    "\n",
    "    with open(os.path.join(output_dir, 'features.tsv'), 'w') as ffile:\n",
    "        for i in range(len(features)):\n",
    "            ffile.write(f\"{feature_ids[i].decode('utf-8')}\\t{features[i].decode('utf-8')}\\t{feature_types[i].decode('utf-8')}\\n\")\n",
    "\n",
    "    scipy.io.mmwrite(os.path.join(output_dir, 'matrix.mtx'), \n",
    "                     scipy.sparse.csc_matrix((filtered_data, filtered_indices, filtered_indptr), shape=filtered_shape))\n",
    "\n",
    "# Function to process samples\n",
    "def process_samples(h5_filename, csv_filenames, csv_atac_filenames, sample_names, output_base_dir):\n",
    "    barcodes, features, feature_ids, feature_types, data, indices, indptr, shape = read_h5_file(h5_filename)\n",
    "    \n",
    "    for csv_filename, csv_atac_filename, sample_name in zip(csv_filenames, csv_atac_filenames, sample_names):\n",
    "        df = pd.read_csv(csv_filename, header=None)\n",
    "        sample_barcodes = df[0].tolist()\n",
    "        \n",
    "        output_dir = os.path.join(output_base_dir, sample_name)\n",
    "        write_files(barcodes, features, feature_ids, feature_types, data, indices, indptr, shape, sample_barcodes, output_dir)\n",
    "\n",
    "        df_atac = pd.read_csv(csv_atac_filename, header=None)\n",
    "        sample_barcodes_atac = df[0].tolist()\n",
    "        output_dir = os.path.join(output_base_dir, \"atac\", sample_name)\n",
    "        write_files(barcodes, features, feature_ids, feature_types, data, indices, indptr, shape, sample_barcodes, output_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sample-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process samples\n",
    "process_samples(h5_filename, csv_filenames, csv_atac_filenames, sample_names, output_base_dir)\n",
    "\n",
    "# Display output files for verification\n",
    "for sample_name in sample_names:\n",
    "    print(f\"Files for sample {sample_name}:\")\n",
    "    sample_output_dir = os.path.join(output_base_dir, sample_name)\n",
    "    for root, dirs, files in os.walk(sample_output_dir):\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of cells in the original filtered_feature_bc_matrix.h5 file compared with the sum of the number of cells extracted for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read barcodes from HDF5 file\n",
    "def count_barcodes_in_h5(h5_filename):\n",
    "    with h5py.File(h5_filename, 'r') as f:\n",
    "        barcodes = f['matrix']['barcodes'][()]\n",
    "        return len(barcodes)\n",
    "\n",
    "# Function to count lines in a file (used for barcodes.tsv)\n",
    "def count_lines(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "# Path to your original HDF5 file\n",
    "h5_filename = 'GLDS-352_snRNA-Seq_filtered_feature_bc_matrix.h5'  # Replace with your .h5 file path\n",
    "\n",
    "# Paths to your extracted barcodes.tsv files for each sample\n",
    "sample_dirs = [\n",
    "    'CR_output/CF1',\n",
    "    'CR_output/CF2',\n",
    "    'CR_output/CF7',\n",
    "    'CR_output/CG8',\n",
    "    'CR_output/CG9'\n",
    "]\n",
    "\n",
    "# Count cells in the original HDF5 file\n",
    "original_cell_count = count_barcodes_in_h5(h5_filename)\n",
    "print(f\"Number of cells in the original HDF5 file: {original_cell_count}\")\n",
    "\n",
    "# Count cells in the extracted barcodes.tsv files for each sample\n",
    "extracted_cell_count = 0\n",
    "for sample_dir in sample_dirs:\n",
    "    barcodes_file = os.path.join(sample_dir, 'barcodes.tsv')\n",
    "    sample_cell_count = count_lines(barcodes_file)\n",
    "    extracted_cell_count += sample_cell_count\n",
    "    print(f\"Number of cells in {barcodes_file}: {sample_cell_count}\")\n",
    "\n",
    "# Print total number of cells in extracted files\n",
    "print(f\"Total number of cells in extracted files: {extracted_cell_count}\")\n",
    "\n",
    "# Compare counts\n",
    "if original_cell_count == extracted_cell_count:\n",
    "    print(\"The number of cells matches between the original HDF5 file and the extracted files.\")\n",
    "else:\n",
    "    print(\"The number of cells does not match. Please check the extracted files and the original HDF5 file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: If these number do not match exactly it could be due to different filtering parameters for GEX and ATACseq barcodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the numbers in the first row of the matrix.mtx file matches the number of features (aka genes) in the features.tsv, the number of barcodes (aka cells) in the barcodes.tsv, and the number of UMIs in the matrix.mtx file, respectively, for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files(sample_dir):\n",
    "    barcodes_file = os.path.join(sample_dir, 'barcodes.tsv')\n",
    "    features_file = os.path.join(sample_dir, 'features.tsv')\n",
    "    matrix_file = os.path.join(sample_dir, 'matrix.mtx')\n",
    "\n",
    "    # Step 1: Read the barcodes.tsv file and count the rows\n",
    "    with open(barcodes_file, 'r') as f:\n",
    "        barcodes_count = sum(1 for line in f)\n",
    "    \n",
    "    # Step 2: Read the features.tsv file and count the rows\n",
    "    with open(features_file, 'r') as f:\n",
    "        features_count = sum(1 for line in f)\n",
    "    \n",
    "    # Step 3: Read the matrix.mtx file and get the values in the first row\n",
    "    with open(matrix_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.startswith('%'):\n",
    "                first_line = line.strip()\n",
    "                break\n",
    "        matrix_info = first_line.split()\n",
    "        if len(matrix_info) >= 3:\n",
    "            matrix_features_count = int(matrix_info[0])\n",
    "            matrix_barcodes_count = int(matrix_info[1])\n",
    "            matrix_data_count = int(matrix_info[2])\n",
    "        else:\n",
    "            raise ValueError(\"The first row of the matrix.mtx file does not contain the expected number of columns.\")\n",
    "\n",
    "    # Step 4: Read the matrix.mtx file and count the rows of data\n",
    "    with open(matrix_file, 'r') as f:\n",
    "        data_count = sum(1 for line in f if not line.startswith('%')) - 1  # subtract 1 to exclude the header row\n",
    "\n",
    "    # Step 5: Compare the counts\n",
    "    if barcodes_count == matrix_barcodes_count and features_count == matrix_features_count and data_count == matrix_data_count:\n",
    "        print(f\"Success: The number of rows in barcodes.tsv ({barcodes_count}), features.tsv ({features_count}), and matrix.mtx data rows ({data_count}) match the values in the matrix.mtx header for {sample_dir}.\")\n",
    "    else:\n",
    "        print(f\"Error: There is a mismatch in {sample_dir}.\")\n",
    "        if barcodes_count != matrix_barcodes_count:\n",
    "            print(f\"  - Barcodes count: {barcodes_count}, expected: {matrix_barcodes_count}\")\n",
    "        if features_count != matrix_features_count:\n",
    "            print(f\"  - Features count: {features_count}, expected: {matrix_features_count}\")\n",
    "        if data_count != matrix_data_count:\n",
    "            print(f\"  - Matrix data rows count: {data_count}, expected: {matrix_data_count}\")\n",
    "\n",
    "def check_all_samples(base_dir, samples):\n",
    "    for sample in samples:\n",
    "        sample_dir = os.path.join(base_dir, sample)\n",
    "        check_files(sample_dir)\n",
    "\n",
    "# Usage\n",
    "base_dir = 'CR_output'\n",
    "samples = ['CF1', 'CF2', 'CF7', 'CG8', 'CG9']\n",
    "check_all_samples(base_dir, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'CR_output/atac'\n",
    "check_all_samples(base_dir, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshoot discrepancies between barcodes.tsv and matrix.mtx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes, features, feature_ids, feature_types, data, indices, indptr, shape = read_h5_file(h5_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_barcodes = pd.read_csv(csv_filenames[2], header=None)[0].tolist()\n",
    "sample_indices = [i for i, barcode in enumerate(barcodes) if barcode.endswith('-2')]\n",
    "sample_indices_old = [i for i, barcode in enumerate(barcodes) if barcode in sample_barcodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices[slice(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices_old[slice(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_indices_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = list(set(sample_indices) - set(sample_indices_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes[4388]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(barcodes[20808], barcodes[28285])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('h5_barcodes.csv', 'w') as outfile:\n",
    "    for b in barcodes:\n",
    "        outfile.write(b+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
